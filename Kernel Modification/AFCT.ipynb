{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["### Utility function for evaluation"],"metadata":{"id":"I3QrMsne_edI"}},{"cell_type":"code","source":["from sklearn.metrics import confusion_matrix, roc_auc_score, roc_curve, auc\n","\n","from sklearn.gaussian_process.kernels import RBF\n","from sklearn.metrics.pairwise import laplacian_kernel, rbf_kernel\n","from copy import deepcopy\n","from sklearn.preprocessing import MinMaxScaler\n","\n","from sklearn.metrics import confusion_matrix\n","\n","def calculate_se_sp(y_true, y_pred):\n","  tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n","  specificity = tn / (tn+fp)\n","  sensitivity = tp / (tp+fn)\n","\n","  return sensitivity, specificity\n","\n","def calculate_se_sp_gmeans_with_threshold_(y_true, y_pred, T=0):\n","  y_pred_class = np.zeros(len(y_pred))\n","  y_pred_class[y_pred > T] = 1\n","  se, sp = calculate_se_sp(y_true, y_pred_class)\n","\n","  return {\"se\": se,\n","          \"sp\": sp,\n","          \"g_mean\": np.sqrt(se * sp),\n","          'T':T\n","          }\n","\n","def calculate_partial_auc(y_true, y_scores, sensitivity_threshold=0.8):\n","\n","    fpr, tpr, thresholds = roc_curve(y_true, y_scores)\n","\n","    idx = np.where(tpr > sensitivity_threshold)\n","\n","    fpr_partial = fpr[idx]\n","    tpr_partial = tpr[idx]\n","\n","    try:\n","\n","      partial_auc = auc(fpr_partial, tpr_partial)\n","\n","    except:\n","      print('auc error')\n","      partial_auc = 0\n","\n","    return partial_auc\n","\n","def evaluate(y_true, y_pred, T=0, se=0.8):\n","  result = calculate_se_sp_gmeans_with_threshold_(y_true, y_pred, T)\n","  partial_auc = calculate_partial_auc(y_true, y_pred, se)\n","  result['partial_auc'] = partial_auc\n","  return result\n","\n","def normalize(df, feature_cols, selected_cols):\n","  features = df[feature_cols].values\n","  features_norm = np.sqrt(np.sum(features**2, axis=1))\n","  features_test = features / features_norm[:, np.newaxis]\n","  return features_test[:, selected_cols]\n","\n","from sklearn.gaussian_process.kernels import Kernel, RBF\n","import numpy as np\n","from scipy.spatial.distance import cdist\n","\n","class RBFKernel(Kernel):\n","\n","    def __init__(self, gamma=1):\n","        self.gamma = gamma\n","\n","    def __call__(self, X, Y=None):\n","        if Y is None:\n","            Y = X\n","        pairwise_sq_dists = cdist(X, Y, 'sqeuclidean')\n","        K = np.exp(-self.gamma * pairwise_sq_dists)\n","        return K\n","\n","    def diag(self, X):\n","        return np.ones(X.shape[0])\n","\n","    def is_stationary(self):\n","        return True"],"metadata":{"id":"nqrSPM_v8OAG"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Below is the code for preprocessing the data. We didn't put the detailed comment as the output should be the same as matlab version"],"metadata":{"id":"uwje9qgw9Glm"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"w69Ot2ol7VOR","outputId":"bb02a26c-55e4-4021-8d4b-856b807e1f8f"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"]}],"source":["#from google.colab import drive\n","#drive.mount('/content/drive/')\n","\n","import pandas as pd\n","import numpy as np\n","\n","feature_cols = [f'x{i}' for i in range(30)]\n","\n","peaks_to_retain = [5, 7, 9, 17, 18, 25, 29, 3, 4, 6, 11, 13, 15, 19, 21, 23, 26, 27, 28]\n","peaks_to_retain = [index - 1 for index in peaks_to_retain]\n","\n","import scipy.io\n","mat = scipy.io.loadmat('/content/drive/MyDrive/Tissue Identification/full_spectra_feature_set_b12g.mat') #path to data\n","\n","import pandas as pd\n","\n","df = pd.DataFrame({\n","    \"patient_id\": mat['batch2_pat_id'].flatten(),\n","    \"target\": mat['batch2_class_id'].flatten(), #<-will be processed later\n","    \"class_id\": mat['batch2_class_id'].flatten()\n","})\n","df_features = pd.DataFrame(mat['batch2_feat'], columns=feature_cols)\n","df = pd.concat((df, df_features), axis=1)\n","df['id'] = df.index\n","df.loc[df['target'] != 1, 'target'] = 0\n","df_patient = df.groupby(['patient_id']).mean().reset_index()[['patient_id', \"target\"]]\n","df_patient.loc[df_patient['target'] > 0, 'target'] = 1\n","df = pd.DataFrame(df[df['class_id'] != 3]).reset_index(drop=True)\n","df_all_train = df.fillna(0).copy()\n","\n","################################################################################\n","\n","df_test = pd.DataFrame({\n","    \"patient_id\": mat['batchg_pat_id'].flatten(),\n","    \"target\": mat['batchg_class_id'].flatten(), #<-will be processed later\n","    \"class_id\": mat['batchg_class_id'].flatten()\n","})\n","df_test_features = pd.DataFrame(mat['batchg_feat'], columns=feature_cols)\n","df_test = pd.concat((df_test, df_test_features), axis=1)\n","df_test['id'] = df_test.index\n","df_test.loc[df_test['target'] != 1, 'target'] = 0\n","df_test = pd.DataFrame(df_test[df_test['class_id'] != 3]).reset_index(drop=True)\n","df_test = df_test.fillna(0)"]},{"cell_type":"code","source":["X_train = normalize(df_all_train, feature_cols, peaks_to_retain)\n","y_train = df_all_train['target'].values\n","\n","X_test = normalize(df_test, feature_cols, peaks_to_retain)\n","y_test = df_test['target'].values"],"metadata":{"id":"pOf3M08G7e7L"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["X_train"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6A9mecMs82E5","outputId":"8205207c-3121-4580-e94f-c82d4aaad81c"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[1.54583271e-02, 2.91736912e-02, 8.84289256e-02, ...,\n","        7.07980251e-01, 5.19300100e-02, 7.84081779e-02],\n","       [1.95770553e-02, 2.91327504e-02, 6.44896192e-02, ...,\n","        6.97096718e-01, 5.49123324e-02, 7.62699631e-02],\n","       [1.44953164e-02, 4.87302605e-02, 3.37123394e-02, ...,\n","        7.01940004e-01, 6.13487237e-02, 7.70064369e-02],\n","       ...,\n","       [7.82731501e-03, 6.77351987e-04, 1.59877729e-01, ...,\n","        7.15674499e-01, 2.85757621e-02, 5.99570575e-02],\n","       [8.05998688e-03, 2.26376013e-03, 1.48850255e-01, ...,\n","        7.31331224e-01, 3.46706430e-02, 6.43027707e-02],\n","       [1.48836374e-02, 1.66577592e-02, 1.04835356e-01, ...,\n","        6.73543535e-01, 3.89907023e-02, 6.18259816e-02]])"]},"metadata":{},"execution_count":7}]},{"cell_type":"code","source":["y_train"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nNak_p4W83P5","outputId":"a47565d0-09e7-42c6-f127-4a80d45898f7"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([1, 1, 1, ..., 0, 0, 0], dtype=uint8)"]},"metadata":{},"execution_count":9}]},{"cell_type":"markdown","source":["### Import Kernel modification SVM to fit and predict\n","The detailed of the code has been comment in the main code `afc.py` in the `afc_imbalanced_learning`"],"metadata":{"id":"ZKU6z8zB87Y_"}},{"cell_type":"code","source":["from afc_imbalanced_learning.afc import AFSCTSvm\n","\n","#using best parameter obtained from cross validation\n","\n","kernel = RBFKernel(0.5)\n","svm = AFSCTSvm(\n","    C=0.01,\n","    class_weight=\"balanced\",\n","    neg_eta=1,\n","    pos_eta=1,\n","    kernel=kernel,\n","    ignore_outlier_svs=True\n",")\n","\n","svm.fit(X_train, y_train)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7_CUlxcr-D9h","outputId":"4b686118-e5b5-4ba4-e64d-8024b2e21b6a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["calculating tau with pos eta: 1 and neg eta: 1\n"]}]},{"cell_type":"code","source":["# get threshold that give 80% of sensitivity on full train set\n","y_train_pred = svm.decision_function(X_train)\n","fpr, tpr, thresholds = roc_curve(y_train, y_train_pred)\n","best_T = thresholds[np.argmax(tpr >= 0.8)]\n","train_results = evaluate(y_train, y_train_pred, best_T)\n","\n","# make a preidiction using raw score\n","y_pred = svm.decision_function(X_test)\n","\n","#evaluate with best threshold\n","final_result = evaluate(y_test, y_pred, best_T)\n","final_result"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uf9iwQ7P-dkJ","outputId":"ee618bb4-5c45-48bc-99ed-a7ce5f8eccd3"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'se': 0.8697674418604651,\n"," 'sp': 0.9121926229508197,\n"," 'g_mean': 0.8907274802923295,\n"," 'T': 1.1912385544929323,\n"," 'partial_auc': 0.9226863324437666}"]},"metadata":{},"execution_count":12}]},{"cell_type":"code","source":[],"metadata":{"id":"O6QBJWFM-1QS"},"execution_count":null,"outputs":[]}]}